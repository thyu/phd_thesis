\chapter{Conclusion}
\label{chap/conclusion}

In this thesis, the problems of object classification and pose estimation from 3D visual data have been studied. This chapter concludes the findings of this research, identifies the limitations of the proposed solutions, and suggests possible directions for future work.  

\section{Findings}

\subsection{3D shape}

In part I, the classification and registration tasks of 3D shape data were investigated. A comprehensive performance evaluation of 3D interest point detectors has been presented in chapter \ref{chap/eval}. A selection of interest point detectors for volumetric data (voxels) were studied both quantitatively and qualitatively. A novel evaluation metric has been introduced to facilitate a fair and holistic comparison, by combining the repeatability score and localisation accuracy of an interest point detector into a unified measurement. The experimental results have shown that, with respect to the proposed evaluation metric, the performance of various 3D interest points is analogous to that of their original image-based counterparts. Among the candidate interest points, region-based blob detectors, \eg MSER, attained highest repeatability in the experiments, followed by derivative-based blob detectors such as DoG or HoG. On the contrary, corner detectors, \eg VFAST and Harris, are suitable for noisy or low-resolution 3D shape data, despite being less stable than other detectors. The 3D interest point detectors also demonstrated different qualitative properties. In summary, the choice of 3D interest point is essentially application dependent. 

Chapter \ref{chap/reg} addressed the sub-problems of 3D shape classification and pose estimation by introducing a shape-appearance-pose (SAP) constellation model. The proposed SAP model learns appearances and locations of object parts in a canonical reference frame in training. On the other hand, SAP model classifies an object and simultaneously registers it to the canonical pose during testing. While existing models require ground truth pose information for training, the proposed SAP algorithm also registers training instances, with unknown initial poses, to the canonical pose during training. Recognition and registration performance of the proposed system was evaluated on both 2D image data and 3D shape data; it demonstrated the feasibility of inferring pose jointly with shape and appearance when training part-based models. 

\subsection{Human action analysis}

In part II, human action classification and pose estimation from spatiotemporal data, \eg videos and sequences of depth images, have been studied. Three new solutions have been proposed for such tasks based on random forest, which is an efficient and versatile machine learning technique for classification, clustering or regression. 

Chapter \ref{chap/act} considered the task of action classification from video. It has presented a novel framework that utilises local appearance and structural information to recognise action class in real-time. Building on the work of Shotton \etal \cite{Shotton2008}, a semantic texton forest (STF) is applied as a powerful discriminative visual codebook. In addition, hierarchical spatiotemporal relationship match (HSRM) has been proposed to describe the structure of an action by encoding the space-time relationship between visual codewords. A k-mean forest classifier has been employed to categorise action classes efficiently, using HSRM as the matching kernel to provide fast and non-linear classification. The proposed system demonstrated real-time performance as well as state-of-the-art accuracy, from experimental results with the KTH and the UT-interaction datasets. 

Chapter \ref{chap/body} investigated the problem of 3D human body pose estimation (3D HPE).
A new 3D HPE framework has been proposed to estimate full 3D human poses from realistic and monocular video data. Different from traditional approaches, poses were not estimated directly from low-level visual features but a combination of high-level (action) and mid-level (2D body parts) cues. 
A deformable part-model was utilised to detect 2D body parts in video, producing mid-level features that were robust to cluttered background and appearance changes. In addition, a new action detection forest has been used to classify and locate actions in space-time, providing high-level semantic information for pose estimation. Joint locations were subsequently refined using a regression forest. A new action and pose dataset has been collected for performance evaluation. Without using multiple calibrated cameras or tracking algorithm, the proposed method demonstrated encouraging accuracy.
%, justifying the feasibility of combining action classification/detection with pose estimation.  

Finally, 3D hand pose estimation was studied in chapter \ref{chap/hand}. Synthetic data have been used by many existing hand pose estimation systems for training. The proposed STR forest captured the benefits of both realistic and synthetic data via transductive learning. The STR forest learns the implicit relationship between a small, sparsely labelled realistic dataset and a large synthetic dataset with generated groundtruths. In addition, a data-driven technique was also proposed to recover noisy and occluded joints. Experimental results demonstrated not only the promising performance of this approach with respect to noise and occlusions, but also its superiority in accuracy, robustness and speed over existing methods.

\section{Limitations}

\subsection{3D shape} 

As mentioned in section \ref{sec/reg/reg}, the problem of unsupervised 3D shape registration is not completely solved, especially for weak features with a low discriminative power. From the experimental results, clusters of object parts were formed by the training instances of different initial poses during the early stage of training. Since the solution space of the SAP model is huge, there is no guarantee that the likelihood would converge to the global maximum. Furthermore, the overly simple 3D descriptor of the \emph{point cloud} dataset may have aggravated the clustering problem.   

While non-linear deformation is handled effectively by state-of-the-art discriminative part-based models \cite{Felzenszwalb2010, Andriluka2009, Pishchulin2012}, the SAP model considers only linear transformation, restricting its applications to rigid objects. 

\subsection{Human actions analysis} 

Occlusion has always been the major limitation of visual based human activity analysis. Complicated and realistic actions are often heavily occluded, appearance and motion information cannot be recovered when a large part of action is occluded or not captured from the camera viewpoint. Despite achieving excellent run-time performance with excellent accuracy, the action classification algorithm in chapter \ref{chap/act} performs on complete and rarely occluded actions, such as the KTH dataset. In addition, the solution is not scale invariant, input videos are required to be normalised with respect to scale. Otherwise, model parameters have to be re-adjusted manually for input videos with different resolutions.  

For human body estimation, the DPM used for feature extraction in chapter \ref{chap/body} does not effectively model occlusions. When a body part is occluded, the DPM often produces false positive detections, without considering whether the part is visible in the scene. Similarly, hand pose estimation in chapter \ref{chap/hand} does not perform properly when self-occlusion is severe. In addition, the data-driven refinement algorithm becomes unreliable under heavy occlusion, when too many unknown joints have to be inferred from a few visible joints. 

On the other hand, human can effortlessly recover occluded poses or partial actions by inferring from the context such as background, speech and interaction with other objects or people in the scene. It is suggested that extra cues are necessary to further improve the accuracy in frequently occluded or partial actions. 

For discriminative pose estimation approaches, such as the solutions proposed in chapter \ref{chap/body} and \ref{chap/hand}, the number of recognisable pose depends on the dataset used in training. While generative methods theoretically handle all poses performed by the articulated model given \cite{Oikonomidis2011}, generic pose estimation is still a challenging problem for discriminative approaches. 

\section{Future work}

Interesting work directions are summarised as follows.

\begin{itemize}
	\item \textbf{Inferring 3D structures from 2D images} \\  
	In chapter \ref{chap/reg}, the SAP constellation model is built from features of the same modality (3D model from shape descriptor, 2D model from image patches). Inspired from the work of Pepik \etal \cite{Pepik2012} and Sun \etal \cite{Sun2009}, it is interesting to design a framework for building a 3D constellation model using 2D images from multiple unknown viewpoints. However, matching part appearances from extreme viewpoints is a challenging problem.  
	\item \textbf{Context-assisted action classification} \\ 
	As mentioned in the previous section, additional cues are essential to improve the accuracy of action recognition, particularly for heavily occluded realistic actions. New action classification algorithms should consider new contextual features which provide extra information outside the target object, \eg Ding and Xiao \cite{Ding2012}.   
	\item \textbf{Real-time pose estimation}\\ 
	Run-time performance is of crucial importance in many computer vision applications. In the proposed body pose estimation framework, DPM is identified as the computation bottleneck in the pipeline. 
	Recent literature has already implemented real-time 3D HPE solutions from depth images, \eg \cite{Baak2011, Girshick2011, Sun2012}, but video-based solution is still absent.  
	Future work should consider methods to make this process real-time, for example by parallelisation, or by simplifying the appearance feature used (HoG is used in the current implementation \cite{Yang2011}).  
	\item \textbf{Hybrid discriminative/generative pose estimation}\\
	While discriminative approaches usually achieve good run-time performance in pose estimation, generative approaches effectively handle unseen poses. The two directions can be combined to a hybrid pose estimation framework. The approach is conceptually similar to Keskin \etal \cite{Keskin2012}, but instead of two layers of random forests, a generative pose estimator is used at the fine grained level. Poses are first estimated efficiently by a discriminative model, at a coarse-grained level, detailed articulations are then inferred by a generative pose estimator. Poses are estimated accurately and efficiently by a generative model, which is initialised by a discriminative pose estimator. In addition, the proposed hybrid method also requires fewer labelled training data for its discriminative part. 
	\item \textbf{Hand pose estimation from high-resolution depth images}\\
	High-resolution, low-noise and real-time time-of-flight cameras have become available recently \cite{Nair2012}. Since they capture high-definition depth images with less missing data, the existing problem of sampling noise will be alleviated. New hand pose estimation algorithms should focus on utilising the high-resolution depth images, in order to provide improved accuracy.  
\end{itemize}

Three-dimensional object recognition have seen substantial improvement over the recent years.
This thesis have answered several unresolved issues in classification and pose estimation of 3D shapes and human actions by presenting various novel solutions to the problems. While there is still a considerable way from fully automatic 3D classification and pose estimation systems, it is believed that this thesis has taken a step towards practical applications. 
