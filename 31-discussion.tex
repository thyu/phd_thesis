\chapter{Conclusion}
\label{chap/conclusion}

In this thesis, the problems of 3D object classification and pose estimation have been studied. This chapter concludes the findings of this research, identifies the limitations of the proposed solutions, and suggests possible directions for future work.  

\section{Findings}

\subsection{3D shape}

The first part of this thesis investigated the classification and registration tasks of 3D shape data. It started with a comprehensive performance evaluation of 3D interest point detectors in chapter \ref{chap/eval}. 
Several volumetric interest point detectors were selected from existing 3D object recognition systems, and their properties were studied quantitatively and qualitatively. 
A novel evaluation metric was proposed to combine the repeatability and accuracy of an interest point into a unified measurement, to make a fair and complete comparison.  
The evaluation results have proved that, with respect to the proposed evaluation metric, the performances of candidate 3D interest points are analogous to that of their original image-based counterparts. Region-based blob detectors, \eg MSER, attained highest repeatability in the experiments, followed by derivative-based blob detectors such as DoG or HoG. Alternatively, corner detectors, \eg VFAST and Harris, were suitable for noisy or low-resolution 3D shape data, despite being less stable than other detectors.  
Nevertheless, the 3D interest points also demonstrated different qualitative properties. Hence, the choice of 3D interest point is essentially application dependent. 

Chapter \ref{chap/reg} addressed classification and pose estimation of 3D geometric shape by introducing a shape-appearance-pose (SAP) constellation model. 
The proposed SAP model learns appearances and locations of object parts within a canonical reference frame in training. Meanwhile in testing, SAP model classifies an object and simultaneously registers it to the canonical pose. 
% While existing models require groundtruth pose information for training, presenting a barrier for potential applications using unlabelled data, \eg from a large un-annotated database, the proposed SAP inference algorithm also estimate object pose, relative to a canonical pose, in both training and testing.  
Recognition and registration performances of the proposed system were evaluated on 2D image data and 3D shape data, demonstrating the feasibility of inferring pose jointly with shape and appearance when training part-based models. 

\subsection{Human action analysis}

In the second part of the thesis, human action classification and pose estimation from spatiotemporal data, \eg videos and sequences of depth images, have been studied. 
It has also presented three new solutions to these tasks based on random forest, which is an efficient and versatile machine learning technique for classification, clustering or regression. 

Chapter \ref{chap/act} considered the task of video-based action classification from video. It presented a novel framework that utilises local appearance and structural information to recognise action class in real-time. Building on the work of Shotton \etal \cite{Shotton2008}, a semantic texton forest (STF) was applied as a powerful discriminative visual codebook. In addition, hierarchical spatiotemporal relationship match (HSRM) was proposed to describe the structure of an action by encoding the space-time relationship between codewords. A k-mean forest classifier was employed to categorise action classes, using HSRM as the matching kernel to provide fast and non-linear classification. 
%From the experimental results, the proposed action recognition framework demonstrated real-time performance as well as state-of-the-art accuracy.  
The proposed system demonstrated real-time performance as well as state-of-the-art accuracy, from experimental results with KTH and UT-interaction datasets. 

Chapter \ref{chap/body} considered the problem of 3D human body pose estimation (3D HPE).
A new 3D HPE framework has been proposed to estimate full 3D human poses from realistic and monocular video data. Different from traditional approaches, poses were not estimated directly from low-level visual features but a combination of high-level (action) and mid-level (2D body parts) cues. 
A deformable part-model was utilised to detect 2D body parts in video, producing mid-level features that were robust to cluttered background and appearance changes. In addition, a new action detection forest has been used to classify and locate actions in space-time, providing high-level semantic information for pose estimation. Joint locations were subsequently refined using a regression forest. A new action and pose dataset has been collected for performance evaluation. Without using multiple calibrated cameras or tracking algorithm, the proposed method demonstrated encouraging accuracy.
%, justifying the feasibility of combining action classification/detection with pose estimation.  

Finally, 3D hand pose estimation was studied in chapter \ref{chap/hand}. 
Existing hand pose estimation systems have been using synthetic data extensively for training. Their performances, however, was undermined by the discrepancies between realistic and synthetic data. As a result, the semi-supervised transductive regression (STR) forest was introduced for real-time articulated hand pose estimation. 
The STR forest captured the benefits of both realistic and synthetic data via transductive learning. 
It learned the implicit relationship between a small, sparsely labelled realistic dataset and a large synthetic dataset. A data-driven technique was also proposed to recover noisy and occluded joints. 
Experimental results demonstrated not only the promising performance of this approach with respect to noise and occlusions, but also its superiority over state-of-the-arts in accuracy, robustness and speed.

\section{Limitations}

\subsection{3D shape} 

As mentioned in section \ref{sec/reg/reg}, the problem of unsupervised 3D shape registration is not completely solved, especially with features of low discriminative power. Clusters of object parts are learned from instances of different poses in the early stage of training. Since the solution space is huge, there is no guarantee that the likelihood would converge to the global maximum. Furthermore, the overly simple 3D descriptor of the \emph{point cloud} dataset may have aggravated the clustering problem.   

While non-linear deformation is handled effectively by state-of-the-art discriminative part-based models \cite{Felzenszwalb2010, Andriluka2009, Pishchulin2012}, the SAP model considers only linear transformation, restricting its applications to rigid objects. 

\subsection{Human actions analysis} 

Occlusion is the major limitation of visual based human activity analysis. 
Complicated and realistic actions are often heavily occluded, appearance and motion information can not be recovered when a large part of action is occluded or not captured. Despite achieving real-time performance with excellent accuracy, the action classification algorithm in chapter \ref{chap/act} performs on complete and rarely occluded actions. 
In addition, the solution is not scale invariant, input videos are required to be normalised with respect to scale. Otherwise, model parameters have to be re-adjusted manually for videos with different resolutions.  

For human body estimation, the DPM used for feature extraction in chapter \ref{chap/body} does not effectively model occlusions. When a body part is occluded, the DPM often produces incorrect detections, without considering whether the part is occluded. Similarly, hand pose estimation in chapter \ref{chap/hand} does not perform properly when self-occlusion is severe, even with the help of data-driven refinement because most pose information is lost. 

On the other hand, human can effortlessly recover occluded poses or partial actions by inferring from the context, \eg background, speech and interaction with other objects or people in the scene. It implies that extra cues are necessary to further improve the accuracy in frequently occluded or partial actions. 

For discriminative pose estimation approaches, such as the solutions proposed in chapter \ref{chap/body} and \ref{chap/hand}, the number of recognisable pose depends on the training dataset used. While generative methods theoretically handle all poses performed by the articulated model \cite{Oikonomidis2011}, generic pose estimation is still a challenging problem for discriminative approaches. 

\section{Future work}

Interesting work directions are summarised as follows.

\begin{itemize}
	\item \textbf{Inferring 3D structures from 2D images} \\  
	In chapter \ref{chap/reg}, the SAP constellation model is built from features of the same modality, \eg 3D model from shape descriptor, or 2D model from image patches. Inspired from the work of Pepik \etal \cite{Pepik2012} and Sun \etal \cite{Sun2009}, it is interesting to design a framework for building a 3D constellation model using 2D images from multiple unknown viewpoints. However, matching part appearances from extreme viewpoints is a challenging problem.  
	\item \textbf{Context-assisted action classification} \\ 
	As mentioned in the previous section, additional cues are essential to improve the accuracy of action recognition, particularly for heavily occluded realistic actions. New action classification algorithms should consider new contextual features which provide extra information outside the target object, \eg Ding and Xiao \cite{Ding2012}.   
	\item \textbf{Real-time pose estimation}\\ 
	Run-time performance is of crucial importance in many computer vision applications. In the proposed body pose estimation framework, DPM is identified as the computation bottleneck in the pipeline. 
	Recent literature has already implemented real-time 3D HPE solutions from depth images, \eg \cite{Baak2011, Girshick2011, Sun2012}, but video-based solution is still absent.  
	Future work should consider methods to make this process real-time, for example by parallelisation, or by simplifying the appearance feature used (HoG is used in the current implementation \cite{Yang2011}).  
	\item \textbf{Hybrid discriminative/generative pose estimation}\\
	While discriminative approaches usually achieve good run-time performance in pose estimation, generative approaches effectively handle unseen poses. The two directions can be combined to a hybrid pose estimation framework. The approach is conceptually similar to Keskin \etal \cite{Keskin2012}, but instead of two layers of random forests, a generative pose estimator is used at the fine grained level. Poses are first estimated efficiently by a discriminative model, at a coarse-grained level, detailed articulations are then inferred by a generative pose estimator. Poses are estimated accurately and efficiently by a generative model, which is initialised by a discriminative pose estimator. In addition, the proposed hybrid method also requires fewer labelled training data for its discriminative part. 
	\item \textbf{Hand pose estimation from high-resolution depth images}\\
	High-resolution, low-noise and real-time time-of-flight cameras have become available recently \cite{Nair2012}. Since they capture high-definition depth images with less missing data, the existing problem of sampling noise will be alleviated. New hand pose estimation algorithm should focus on utilising the high-resolution depth images to provide improved accuracy.  
\end{itemize}

Three-dimensional object recognition have seen substantial improvement over the recent years.
This thesis have answered several unresolved issues in classification and pose estimation of 3D shapes and human actions by presenting various novel solutions to the problems. While there is still a considerable way from fully automatic 3D classification and pose estimation systems, it is believed that this thesis has taken a step towards practical applications.  
