\chapter{Conclusion}
\label{chap/conclusion}

This thesis has studied the problems of 3D object classification and pose estimation in computer vision. 

\section{Findings}

\subsection{3D shapes}

The first part of this thesis investigated the classification and registration tasks of 3D shape data. It started with a comprehensive performance evaluation of 3D interest point detectors in chapter \ref{chap/eval}. Several volumetric interest points were chosen from state-of-the-art 3D object recognition tasks, and their properties were analysed both quantitatively and qualitatively. 
A novel evaluation metric was proposed to combine the repeatability and accuracy of an interest point into one measurement for a fair comparison.  
The evaluation results have proved that, with respect to the proposed evaluation metric, the candidate 3D interest points are analogous to their original image-based counterparts. Region-based blob detectors, \eg MSER, attained highest repeatability in the experiments, followed by derivative-based blob detectors such as DoG or HoG. Alternatively, corner detectors, \eg VFAST and Harris, were suitable for noisy or low-resolution 3D shape data.  
Nevertheless, the 3D interest points also demonstrated other different qualitative properties. Hence, the choice of 3D interest point is essentially application dependent. 

Chapter \ref{chap/reg} addressed the problem of classification and pose estimation of 3D shape by introducing a shape-appearance-pose (SAP) constellation model. While existing models require groundtruth pose information for training, presenting a barrier for potential applications using unlabelled data, \eg from a large un-annotated database, the proposed SAP inference algorithm also estimate object pose, relative to a canonical pose, in both training and testing.  
Recognition and registration performances of the proposed system were evaluated on 2D image data and 3D shape data, demonstrating the feasibility of inferring pose jointly with shape and appearance when training part-based models. 

\subsection{Human action analysis}

In the second part of the thesis, human action classification and pose estimation from spatiotemporal data, \eg videos and sequences of depth images, have been studied. 
It has also presented several new solutions to these tasks based on random forest, which is an efficient and versatile machine learning technique for classification, clustering or regression. 

Chapter \ref{chap/act} considered the task of video-based action classification from video. It also presented a novel framework that utilises local appearance and structural information to recognise action class in real-time. Building on the success of \cite{Shotton2008}, a semantic texton forest (STF) was applied as a powerful discriminative visual codebook. In addition, hierarchical spatiotemporal relationship match (HSRM) was proposed to describe the structure of an action by encoding the space-time relationship between codewords. A k-mean forest classifier was employed to categorise action classes, using HSRM as the matching kernel.   
In the experiments using KTH and UT-interaction dataset, the proposed action recognition system demonstrated real-time performance as well as state-of-the-art accuracy. 

Chapter \ref{chap/body} discussed the problem of 3D human body pose estimation (3D HPE).
A new 3D HPE framework has been proposed to estimate full 3D human poses from realistic and monocular video data. Different from traditional approaches, poses were not estimated directly from low-level visual features but a combination of high-level and mid-level cues. 
A deformable part-model was utilised to detect 2D body parts in video, providing mid-level features that were robust to cluttered background and appearance changes. In addition, a new action detection forest has been proposed to classify and locate actions in space-time, providing high-level semantic information for pose estimation. Joint locations were subsequently refined using a regression forest. A new action and pose dataset has been collected to evaluate the performance of the proposed 3D HPE system. Without using multiple calibrated cameras or tracking algorithm, the proposed method demonstrated the feasibility of combining action classification/detection with pose estimation.  

Finally, 3D hand pose estimation has been studied in chapter \ref{chap/hand}. 
Existing hand pose estimation system have been using synethetic data extensively for training. Their performances, however, could be undermined by the discrepancies between realistic and synthetic data. Addressing these problems, the semi-supervised transductive regression (STR) forest was introduced for real-time articulated hand pose estimation. The STR forest learnt the relationship between a small, sparsely labelled realistic dataset and a large synthetic dataset. A data-driven technique was also proposed to refine noisy and occluded joints. The STR forest captured the benefits of both realistic and synthetic data via transductive learning. 
Experimental results demonstrated not only the promising performance of this approach with respect to noise and occlusions, but also its superiority over state-of-the-arts in accuracy, robustness and speed.

\section{Limitations}

\subsection{3D shapes} 

As mentioned in section \ref{sec/reg/reg}, the problem of unsupervised 3D shape registration is not completely solved. Clusters of object parts are learnt from instances of different poses in the early stage of training. Since the solution space is huge, there is no guarantee that the likelihood would converge to the global maximum. Furthermore, the overly simple 3D descriptor of the \emph{point cloud} dataset may have aggravated the clustering problem.   

While non-linear deformation is effective handled by state-of-the-art discriminative part-based models, \eg \cite{Felzenszwalb2010, Andriluka2009, Pishchulin2012}, the SAP model is considers only linear transformation, restricting its applications to rigid objects. 

\subsection{Human actions analysis} 

Occlusion is the major limitation of visual based human activity analysis. 
Complicated and realistic actions are often heavily occluded, appearance and motion information can not be recovered when a part of action is occluded or not captured. Despite achieving real-time performance with excellent accuracy, the action classification algorithm in chapter \ref{chap/act} performs on complete and rarely occluded actions. 

For human body estimation, the DPM used for feature extraction in chapter \ref{chap/body} does not effectively model part occlusion. When a part is occluded, the DPM produces incorrect detections, without considering whether the part is occluded. Similarly, hand pose estimation in chapter \ref{chap/hand} does not perform properly when self-occlusion is severe, even with the help of data-driven refinement. 

On the other hand, human can effortlessly recover occluded pose or partial actions by inferring from the context, \eg background, speech and interactions with objects or other people in the scene. It implies that extra cues are necessary to further improve the accuracy in frequently occluded or partial actions. 

Discriminative approaches, such as the pose estimators presented in chapter \ref{chap/body} and \ref{chap/hand}, the number of recognisable pose depends on the training dataset used. While generative methods theoretically handle all poses performed by the articulated model, \eg \cite{Oikonomidis2011}, generic pose estimation is a challenging problem for discriminative approaches. 

\section{Future work}

Interesting work directions are summarised as follows.

\begin{itemize}
	\item \textbf{Inferring 3D structures from 2D images~} 
		In chapter \ref{chap/reg}, a SAP constellation model is built from features of the same modality, \eg 3D model from shape descriptor. Inspired from Pepik \etal \cite{Pepik2012} and Sun \etal \cite{Sun2009}, it is interesting to design a framework for building a 3D constellation model using 2D images from multiple unknown viewpoints.  
	\item \textbf{Context-assisted action classification} As mentioned above, additional cues are essential to improve the accuracy of action recognition, particularly for frequently occluded realistic actions. New action classification algorithms should consider new contextual features extracted from input videos, such as Ding and Xiao \cite{Ding2012}.   
	\item \textbf{Real-time pose estimation~} Run-time performance is of crucial importance in many computer vision applications. In the proposed body pose estimation framework, DPM is identified as the computation bottleneck in the pipeline. Future work should consider methods to make this process real-time, for example by parallelisation, or by simplifying the appearance feature used (HoG is used in the current implementation \cite{Yang2011}).  
	\item \textbf{Hybrid discriminative/generative pose estimation~} While discriminative approaches usually achieve good run-time performance in pose estimation, generative approaches effectively handle unseen poses. The two directions can be combined to a hybrid pose estimation framework. The approach is conceptually similar to \cite{Keskin2012}, but instead of two layers of random forests, a generative pose estimator is used at the fine grained level. Poses are first estimated efficiently by a discriminative model, at a coarse-grained level, detailed articulations are then inferred by a generative pose estimator. Poses are estimated accurately and efficiently by a generative model, which is initialised by a discriminative pose estimator. In addition, the proposed hybrid method also requires fewer labelled training data for its discriminative part. 
	\item \textbf{Hand pose estimation from high-resolution depth images~} With the advent of sensor fusion techniques, high-resolution, real-time time-of-flight camera has become available recently \cite{Nair2012}. The existing problem of sampling noise in depth image will be alleviated. New hand pose estimation algorithm should focus on utilising the high-resolution depth images captured.    
\end{itemize}

Three-dimensional object recognition have seen substantial improvement over the recent years.
The solutions presented in this thesis have answered several unresolved issues in classification and pose estimation of 3D shapes and human actions. While there is still a considerable way from fully automatic 3D classification and pose estimation systems, it is believed that this thesis has taken a step towards practical applications.  
